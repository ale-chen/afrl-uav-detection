{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.io import read_image\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import time\n",
    "from rich.progress import Progress, TextColumn, BarColumn, TimeRemainingColumn, MofNCompleteColumn\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav_directory = \"E:\\\\UAV_DISTASIO_DATA\\\\X\\\\ESCAPE_FORMAT_ONECHANNEL\"\n",
    "\n",
    "# label_spreadsheet = \"E:\\\\UAV_DISTASIO_DATA\\\\y\\\\escape_singleUAV_scenarios_cleaned.xlsx\"\n",
    "\n",
    "# # Read the existing label spreadsheet\n",
    "# df_labels = pd.read_excel(label_spreadsheet, header=None, names=[\"filename\", \"type\", \"motion\"])\n",
    "\n",
    "# # Extract the unique identifiers (sA1r01) from the label filenames\n",
    "# df_labels[\"identifier\"] = df_labels[\"filename\"].str.extract(r\"(sA\\d+r\\d+)\")\n",
    "\n",
    "# wav_files = [file for file in os.listdir(wav_directory) if file.endswith(\".wav\")]\n",
    "\n",
    "# # Create a new DataFrame to store the entries for each .wav file\n",
    "# df_entries = pd.DataFrame(columns=[\"filename\", \"type\", \"motion\"])\n",
    "\n",
    "# # Iterate over each .wav file\n",
    "# for wav_file in wav_files:\n",
    "#     # Extract the identifier (sA1r01) from the .wav filename\n",
    "#     identifier = wav_file.split(\"-\")[0]\n",
    "    \n",
    "#     try:\n",
    "#         # Find the corresponding label in the label DataFrame\n",
    "#         label_row = df_labels[df_labels[\"identifier\"] == identifier].iloc[0]\n",
    "        \n",
    "#         # Create a new DataFrame for the current entry\n",
    "#         entry_df = pd.DataFrame({\n",
    "#             \"filename\": [wav_file],\n",
    "#             \"type\": [label_row[\"type\"]],\n",
    "#             \"motion\": [label_row[\"motion\"]]\n",
    "#         })\n",
    "        \n",
    "#         # Concatenate the new entry DataFrame with the existing DataFrame\n",
    "#         df_entries = pd.concat([df_entries, entry_df], ignore_index=True)\n",
    "        \n",
    "#     except IndexError:\n",
    "#         print(f\"No corresponding label found for file: {wav_file}\")\n",
    "#         continue\n",
    "\n",
    "# # Save the new DataFrame to a new Excel spreadsheet\n",
    "# output_spreadsheet = \"E:\\\\UAV_DISTASIO_DATA\\\\y\\\\UAV_chunk_labels.xlsx\"\n",
    "# df_entries.to_excel(output_spreadsheet, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, excel_file, audio_dir, transform=None, target_transform=None):\n",
    "        self.df = pd.read_excel(excel_file)\n",
    "        self.audio_dir = audio_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.label_map = {1: \"Inspired Flight 1200\", 2: \"DJI Matrice 800\", 3: \"DJI Phantom 4 Pro v2\", 5: \"Phantom and Matrice\"}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        audio_path = os.path.join(self.audio_dir, self.df.iloc[idx, 0])\n",
    "        label = self.df.iloc[idx, 1]\n",
    "        \n",
    "        waveform, sample_rate = torchaudio.load(audio_path)\n",
    "        \n",
    "        # Resample the waveform if necessary\n",
    "        if sample_rate != 44100:\n",
    "            waveform = torchaudio.transforms.Resample(sample_rate, 44100)(waveform)\n",
    "        \n",
    "        # Convert waveform to spectrogram\n",
    "        spectrogram = torchaudio.transforms.Spectrogram()(waveform)\n",
    "        \n",
    "        # Convert spectrogram to grayscale tensor\n",
    "        grayscale_spectrogram = spectrogram.mean(dim=0).unsqueeze(0)\n",
    "        \n",
    "        if self.transform:\n",
    "            grayscale_spectrogram = self.transform(grayscale_spectrogram)\n",
    "        \n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        \n",
    "        return grayscale_spectrogram, torch.tensor(label)\n",
    "    \n",
    "    \n",
    "    def save_spectrograms_as_tensors(self, output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        for idx in range(len(self)):\n",
    "            spectrogram, label = self[idx]\n",
    "            \n",
    "            # Convert label to string\n",
    "            label_str = self.label_map.get(label.item(), f\"Unknown_{label.item()}\")\n",
    "            \n",
    "            # Generate filename\n",
    "            filename = f\"spectrogram_{idx}_{label_str}.pt\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            \n",
    "            # Save the spectrogram tensor\n",
    "            torch.save(spectrogram, filepath)\n",
    "            \n",
    "            print(f\"Saved spectrogram tensor: {filepath}\")\n",
    "\n",
    "# Usage example\n",
    "excel_file = \"E:\\\\UAV_DISTASIO_DATA\\\\y\\\\UAV_chunk_labels.xlsx\"\n",
    "audio_dir = r\"E:\\UAV_DISTASIO_DATA\\X\\ESCAPE_FORMAT_ONECHANNEL\"\n",
    "\n",
    "# Define any additional transformations if needed\n",
    "transform = None\n",
    "target_transform = None\n",
    "\n",
    "# Usage example\n",
    "excel_file = \"E:\\\\UAV_DISTASIO_DATA\\\\y\\\\UAV_chunk_labels.xlsx\"\n",
    "audio_dir = r\"E:\\UAV_DISTASIO_DATA\\X\\ESCAPE_FORMAT_ONECHANNEL\"\n",
    "\n",
    "# Define any transformations if needed\n",
    "transform = None\n",
    "target_transform = None\n",
    "\n",
    "dataset = SpectrogramDataset(excel_file, audio_dir, transform=transform, target_transform=target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(.8 * len(dataset))\n",
    "test_size = int(.75 * len(dataset) - train_size)\n",
    "val_size = len(dataset) - train_size - test_size\n",
    "\n",
    "train_dataset, test_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, test_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    "    )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "val_size = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 201, 1103])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(400)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, (5, 10), stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 4, (5, 10), stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((5, 10), stride=(1, 5)),\n",
    "\n",
    "            nn.Conv2d(4, 8, (10, 5), stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 8, (10, 5), stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((10, 5), stride=(2, 3)),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(101 * 74 * 8, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1024, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.seq(x)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_seconds(seconds):\n",
    "    minutes = seconds // 60\n",
    "    hours = minutes // 60\n",
    "    days = hours // 24\n",
    "    return seconds % 60, minutes % 60, hours % 24, days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Define model\n",
    "    model = CNN()\n",
    "    # Cuda setup\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    print(f\"Using device: {device}\")\n",
    "    # Optimizer setup\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "   \n",
    "    # Loss function\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "   \n",
    "    # Number of epochs\n",
    "    num_epochs = 8\n",
    "   \n",
    "    # Train or load model?\n",
    "    model.train()\n",
    "    train_model = True\n",
    "    print(\"Training model....\")\n",
    "    start = time.time()\n",
    "   \n",
    "    if train_model:\n",
    "        with Progress(\n",
    "            TextColumn(\"[progress.description]{task.description}\"),\n",
    "            BarColumn(),\n",
    "            MofNCompleteColumn(),\n",
    "            TimeRemainingColumn(),\n",
    "            refresh_per_second=10\n",
    "        ) as progress:\n",
    "            epoch_task = progress.add_task(\"[cyan]Epochs\", total=num_epochs)\n",
    "            batch_task = progress.add_task(\"[green]Batches\", total=len(train_loader), visible=False)\n",
    "            for epoch in range(num_epochs):\n",
    "                progress.update(batch_task, visible=True, completed=0, total=len(train_loader))\n",
    "                progress.update(epoch_task, advance=1)\n",
    "                total_loss = 0\n",
    "               \n",
    "                for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                   \n",
    "                    # CNN forward pass\n",
    "                    probabilities = model(images)\n",
    "                    loss = loss_fn(probabilities, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                   \n",
    "                    total_loss += loss.item()\n",
    "                    progress.update(batch_task, advance=1)\n",
    "                    progress.refresh()\n",
    "               \n",
    "                avg_loss = total_loss / len(train_loader)\n",
    "                progress.print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "                progress.update(batch_task, visible=False)\n",
    "       \n",
    "        torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "    else:\n",
    "        state = torch.load(\"mnist_cnn.pt\", map_location=torch.device(device))\n",
    "        model.load_state_dict(state)\n",
    "   \n",
    "    end = time.time()\n",
    "    seconds, minutes, hours, days = split_seconds(end - start)\n",
    "    print(f\"Training Runtime: {int(days)}d {int(hours)}h {int(minutes)}m {seconds:.2f}s\")\n",
    "   \n",
    "    # Evaluate model on test data\n",
    "    model.eval()\n",
    "    print(\"Evaluating model....\")\n",
    "    start = time.time()\n",
    "    num_test = 0\n",
    "    num_correct = 0\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        with Progress(\n",
    "            TextColumn(\"[progress.description]{task.description}\"),\n",
    "            BarColumn(),\n",
    "            MofNCompleteColumn(),\n",
    "            TimeRemainingColumn(),\n",
    "            refresh_per_second=10\n",
    "        ) as progress:\n",
    "            test_task = progress.add_task(\"[yellow]Testing\", total=len(test_loader))\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                probabilities = model(images)\n",
    "                _, preds = probabilities.max(1)\n",
    "                num_test += labels.size(0)\n",
    "                num_correct += preds.eq(labels).sum().item()\n",
    "                progress.update(test_task, advance=1)\n",
    "                progress.refresh()\n",
    "   \n",
    "    print(f\"Test accuracy: {num_correct / num_test * 100:.2f}%\")\n",
    "    end = time.time()\n",
    "    seconds, minutes, hours, days = split_seconds(end - start)\n",
    "    print(f\"Testing Runtime: {int(days)}d {int(hours)}h {int(minutes)}m {seconds:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e2038443894c70a758362c6a9af68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Training model....\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save spectrograms as tensors\n",
    "# dataset.save_spectrograms_as_tensors(output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
