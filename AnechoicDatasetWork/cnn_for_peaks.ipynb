{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim import Adam\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, target_transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.label_map = {\n",
    "            'DJIM600': 0,\n",
    "            'DJIS1000': 1,\n",
    "            'DJIS1000LOUD': 2,\n",
    "            'MAVIC2PRO': 3,\n",
    "            'MAVICPRO': 4,\n",
    "            'MAVICPROPLAT': 5,\n",
    "            'PHANTOM4': 6,\n",
    "            'PHANTOM4QP': 7,\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        features = torch.FloatTensor(self.df.iloc[idx, 2])\n",
    "        label = self.df.iloc[idx, 1]\n",
    "        \n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        \n",
    "        return torch.tensor(features), torch.tensor(label)\n",
    "\n",
    "# Usage example\n",
    "csv_file = \"./AnechoicPeaks.csv\"\n",
    "\n",
    "# Define any transformations if needed\n",
    "transform = None\n",
    "target_transform = None\n",
    "\n",
    "dataset = FeatureDataset(csv_file, transform=transform, target_transform=target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x0000020A483F18E0>\n",
      "(tensor([ 38.2269, 103.0592, 110.6002,  ...,   0.3175,   0.3175,   0.3175]), tensor(3))\n"
     ]
    }
   ],
   "source": [
    "train_size = int(.95 * len(dataset)) # CHANGE BASED ON SIZE OF DATASET\n",
    "test_size = int(.75 * (len(dataset) - train_size))\n",
    "val_size = len(dataset) - train_size - test_size\n",
    "\n",
    "train_dataset, test_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, test_size, val_size])\n",
    "print(train_dataset)\n",
    "print(train_dataset[0])\n",
    "\n",
    "#COUNTS PER CLASS --> ([ 933., 1713.,  405., 1241., 1257., 1233., 1237., 1245.])\n",
    "label_num = [ 933., 1713.,  405., 1241., 1257., 1233., 1237., 1245.]\n",
    "label_weights = torch.FloatTensor([1 / num for num in label_num]).to(device)\n",
    "\n",
    "# Using torch.utils.data.weightedRandomSampler to deal with non-uniform dataset\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    "    # sampler=WeightedRandomSampler(weights=label_weights, num_samples=train_size, replacement=True)\n",
    "    )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 1, 1, 7, 4, 1, 1, 3, 0, 7, 6, 6, 1, 5, 7, 6, 7, 7, 1, 6, 3, 3, 0, 3,\n",
      "        6, 6, 6, 1, 4, 4, 4, 2, 1, 4, 3, 3, 5, 4, 5, 7, 5, 5, 0, 3, 4, 5, 6, 6,\n",
      "        1, 7, 0, 7, 3, 6, 6, 1, 7, 3, 7, 3, 5, 7, 6, 3, 3, 6, 7, 3, 6, 6, 5, 2,\n",
      "        7, 6, 1, 4, 4, 4, 6, 5, 3, 1, 1, 2, 7, 1, 5, 0, 3, 7, 5, 1, 7, 6, 7, 4,\n",
      "        2, 5, 4, 6, 6, 7, 6, 1, 5, 3, 5, 3, 6, 6, 3, 6, 7, 6, 1, 7, 6, 4, 5, 0,\n",
      "        1, 3, 6, 6, 6, 1, 3, 3])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataset.py:419\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m, in \u001b[0;36mFeatureDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(idx):\n\u001b[0;32m     22\u001b[0m     idx \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m---> 23\u001b[0m features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mDoubleTensor(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     24\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexing.py:1692\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1690\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n\u001b[0;32m   1691\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m-> 1692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_lowerdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexing.py:1065\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tup):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_label_like(key):\n\u001b[0;32m   1063\u001b[0m         \u001b[38;5;66;03m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m         \u001b[38;5;66;03m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[1;32m-> 1065\u001b[0m         section \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1067\u001b[0m         \u001b[38;5;66;03m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m         \u001b[38;5;66;03m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m         \u001b[38;5;66;03m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m section\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m   1071\u001b[0m             \u001b[38;5;66;03m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m             \u001b[38;5;66;03m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\indexing.py:1754\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[1;32m-> 1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\frame.py:3996\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[1;34m(self, i, axis)\u001b[0m\n\u001b[0;32m   3994\u001b[0m \u001b[38;5;66;03m# irow\u001b[39;00m\n\u001b[0;32m   3995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3996\u001b[0m     new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_xs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3998\u001b[0m     \u001b[38;5;66;03m# if we are a copy, mark as such\u001b[39;00m\n\u001b[0;32m   3999\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(new_mgr\u001b[38;5;241m.\u001b[39marray, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m new_mgr\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\internals\\managers.py:1002\u001b[0m, in \u001b[0;36mBlockManager.fast_xs\u001b[1;34m(self, loc)\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;66;03m# Such assignment may incorrectly coerce NaT to None\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m     \u001b[38;5;66;03m# result[blk.mgr_locs] = blk._slice((slice(None), loc))\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, rl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(blk\u001b[38;5;241m.\u001b[39mmgr_locs):\n\u001b[1;32m-> 1002\u001b[0m         result[rl] \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[0;32m   1005\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mconstruct_array_type()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\internals\\blocks.py:1253\u001b[0m, in \u001b[0;36mBlock.iget\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshape\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Shape:\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m-> 1253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miget\u001b[39m(\u001b[38;5;28mself\u001b[39m, i: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mslice\u001b[39m, \u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;66;03m# In the case where we have a tuple[slice, int], the slice will always\u001b[39;00m\n\u001b[0;32m   1255\u001b[0m     \u001b[38;5;66;03m#  be slice(None)\u001b[39;00m\n\u001b[0;32m   1256\u001b[0m     \u001b[38;5;66;03m# Note: only reached with self.ndim == 2\u001b[39;00m\n\u001b[0;32m   1257\u001b[0m     \u001b[38;5;66;03m# Invalid index type \"Union[int, Tuple[int, int], Tuple[slice, int]]\"\u001b[39;00m\n\u001b[0;32m   1258\u001b[0m     \u001b[38;5;66;03m# for \"Union[ndarray[Any, Any], ExtensionArray]\"; expected type\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;66;03m# \"Union[int, integer[Any]]\"\u001b[39;00m\n\u001b[0;32m   1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues[i]  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_slice\u001b[39m(\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28mself\u001b[39m, slicer: \u001b[38;5;28mslice\u001b[39m \u001b[38;5;241m|\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_] \u001b[38;5;241m|\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp]\n\u001b[0;32m   1264\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for feature, label in train_loader:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[400][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.LazyLinear(1024),\n",
    "            nn.LazyBatchNorm1d(),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(1024),\n",
    "            nn.LazyBatchNorm1d(),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(512),\n",
    "            nn.LazyBatchNorm1d(),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(256),\n",
    "            nn.LazyBatchNorm1d(),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(8)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.seq(x)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_seconds(seconds):\n",
    "    minutes = seconds // 60\n",
    "    hours = minutes // 60\n",
    "    days = hours // 24\n",
    "    return seconds % 60, minutes % 60, hours % 24, days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def main():\n",
    "    # Define model\n",
    "    model = LNN()\n",
    "    # Cuda setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #device = torch.device(\"cpu\")\n",
    "    model = model.to(device)\n",
    "   \n",
    "    print(f\"Using device: {device}\")\n",
    "    # Optimizer setup\n",
    "    optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "   \n",
    "    # Loss function\n",
    "    #COUNTS PER CLASS --> ([ 933., 1713.,  405., 1241., 1257., 1233., 1237., 1245.])\n",
    "    label_num = [ 933., 1713.,  405., 1241., 1257., 1233., 1237., 1245.]\n",
    "    label_weights = torch.FloatTensor([1 / num for num in label_num]).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "   \n",
    "    # Number of epochs\n",
    "    num_epochs = 64\n",
    "   \n",
    "    # Train or load model?\n",
    "    print(\"Training model....\")\n",
    "    start = time.time()\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "       \n",
    "        model.train()\n",
    "        for batch_idx, (features, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)):\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "           \n",
    "            # CNN forward pass\n",
    "            probabilities = model(features)\n",
    "            loss = loss_fn(probabilities, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        num_test = 0\n",
    "        num_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for features, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                probabilities = model(features)\n",
    "                _, preds = probabilities.max(1)\n",
    "                num_test += labels.size(0)\n",
    "                num_correct += preds.eq(labels).sum().item()\n",
    "    \n",
    "        tqdm.write(f\"Epoch {epoch+1}/{num_epochs}, Test accuracy: {num_correct / num_test * 100:.2f}\")\n",
    "\n",
    "        torch.save(model.state_dict(), f\"./peaks_models/_epoch_{str(epoch)}.pt\")\n",
    "   \n",
    "    end = time.time()\n",
    "    seconds, minutes, hours, days = split_seconds(end - start)\n",
    "    print(f\"Training Runtime: {int(days)}d {int(hours)}h {int(minutes)}m {seconds:.2f}s\")\n",
    "   \n",
    "    # Evaluate model on validation data\n",
    "    model.eval()\n",
    "    print(\"Evaluating model....\")\n",
    "    start = time.time()\n",
    "    num_test = 0\n",
    "    num_correct = 0\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for features, labels in tqdm(val_loader, desc=\"Validating\"):\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            probabilities = model(features)\n",
    "            _, preds = probabilities.max(1)\n",
    "            num_test += labels.size(0)\n",
    "            num_correct += preds.eq(labels).sum().item()\n",
    "   \n",
    "    print(f\"Test accuracy: {num_correct / num_test * 100:.2f}%\")\n",
    "    end = time.time()\n",
    "    seconds, minutes, hours, days = split_seconds(end - start)\n",
    "    print(f\"Testing Runtime: {int(days)}d {int(hours)}h {int(minutes)}m {seconds:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Training model....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3f1319aae54594a83c13133d12120a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77faaee0be6f4b31b70006143915f346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/64:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4952ee100a0a431a958e9ee49ede1934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model....\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 25.40%\n",
      "Testing Runtime: 0d 0h 0m 2.33s\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = LNN()\n",
    "# Cuda setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Optimizer setup\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "state = torch.load(r\"C:\\Users\\Alec\\Desktop\\afrl-uav-detection\\classify\\1719597586.3545992_epoch_0.pt\")\n",
    "model.load_state_dict(state)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "print(\"Evaluating model....\")\n",
    "start = time.time()\n",
    "num_test = 0\n",
    "num_correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    with Progress(\n",
    "        TextColumn(\"[progress.description]{task.description}\"),\n",
    "        BarColumn(),\n",
    "        MofNCompleteColumn(),\n",
    "        TimeRemainingColumn(),\n",
    "        refresh_per_second=10\n",
    "    ) as progress:\n",
    "        test_task = progress.add_task(\"[yellow]Testing\", total=len(test_loader))\n",
    "        for audio_file, images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            probabilities = model(images)\n",
    "            _, preds = probabilities.max(1)\n",
    "            num_test += labels.size(0)\n",
    "            num_correct += preds.eq(labels).sum().item()\n",
    "            progress.update(test_task, advance=1)\n",
    "            progress.refresh()\n",
    "\n",
    "print(f\"Test accuracy: {num_correct / num_test * 100:.2f}%\")\n",
    "end = time.time()\n",
    "seconds, minutes, hours, days = split_seconds(end - start)\n",
    "print(f\"Testing Runtime: {int(days)}d {int(hours)}h {int(minutes)}m {seconds:.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
